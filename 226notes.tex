\documentclass{report}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

% Definitions / Theorems
%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{thm}{Theorem}
%%%%%%%%%%%%%%%%%%%%%%

% Examples
%%%%%%%%%%%%%%%%%%%%%%
\newtheorem*{remark*}{Example}
\newtheorem*{definition*}{Meaning}
%%%%%%%%%%%%%%%%%%%%%%

% Misc
%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{plain}{Symbol}
%%%%%%%%%%%%%%%%%%%%%%

% Real Numbers
%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
%%%%%%%%%%%%%%%%%%%%%%

\title{Math\_226 (Spring 2023) Notes}
\author{Randy Truong}
\begin{document}
\maketitle
\begin{sloppypar}
  \tableofcontents

% Sequences (Part One)
\chapter{10.1 (Part One): Sequences (Part One) (03/28/23)}
\section{Reminders}
\begin{itemize}
  \item The first MyLab homework is due on
        \textbf{Wednesday, March 28, 2023}.
        \begin{itemize}
                \item Series (Part 0)
        \end{itemize}
  \item The first \textbf{written homework} is going to
        be due on \textbf{Friday, March 31, 2023}.

\end{itemize}

\section{Objectives}
\begin{itemize}
  \item We want to be able to derive the concept of a
        series and a sequence.
  \item We want to be able to understand
        where the idea of a series and sequence come from,
        especially from seemingly-ordinary objects.
  \item We want to explore the idea of a limit
        in relation to a sequence.
  \item We want to be able to discretely express
        a sequence.

\end{itemize}

\section{Motivation}
In former calculus classes, we have observed the idea of limits, derivatives, and integrals at face value. We
know how to evaluate these different calculations, but
what exactly do they mean in the context of math? How can
we better observe what exactly happens in these calculations,
and understand them outside the context of visualizing graphs
or projectile motion.
\section{A third...}

% Sequences (Part Two)
\chapter{10.1 (Part Two): Sequences (Part Two) (03/29/23)}
\section{Reminders}
\begin{itemize}
  \item MyLab Math Assignment 1 - \textbf{Sequences (Part 0)} is
        due \textbf{tonight, March 29, 2023}.
  \item Written Homework 1 is due \textbf{Friday, March 31,
        2023} at the \textbf{beginning of class}.
  \item Friday's lesson is going to be over \textbf{sections
        4.6 and 10.1} and we will be talking about \textbf{
        Newton's Method. }
\end{itemize}
\subsection{Course Philosophy}
Remember that the entire point of this class is to develop
an intuition and a larger understanding and appreciation of
calculus.
\begin{center}
  \textit{``Calculus is just algebra with a tiny drop of
    limits''}
\end{center}
\section{Motivation}
In the last class, we got our first taste of sequences
by exploring the idea of a third and eventually relating it
to the \textbf{geometric sequence}, which results in the formula
of
\[ a_{n} = \frac{1}{1-x}\]
In this class, we were essentially taking our ``preview'' of
sequences, actually defining different aspects of our sequence,
doing operations on sequences, and finally, exploring
one of the most important ideas of sequences, which are
limit convergence divergence, which led us to the famous
$ \varepsilon - N $ proof, which is also known as the \textbf{precise
definition of convergence.}
\section{Sequences}
\begin{center}
  \fbox {
    \parbox{\textwidth} {
      \begin{definition}
        Sequences
      \end{definition}
      A function with a domain of natural numbers and a co-domain
      of real numbers.
      \[ f: \N \rightarrow \R \]
      \begin{definition*}
      \end{definition*}
      \par Although our intuition would tell us that a sequence
        is just a list or a collection of numbers,
        a sequence is more precisely just a function in which
        we input an \textbf{index} (a natural number) and we
        output a \textbf{term} (a real number). We, of course,
        then, collect these outputs, and this is what we
        generally see.
        \begin{remark*}
          \[ \{ a_{n} \}\]
          \[ \{ a_{n}\}_{n=1}^{\infty}\]
          \[ \{ a_{n}\}_{n=0}^{\infty}\]
          \[ 1, 2, 3, 4, \dots\]
          \[ 1.1, 2.2, 3.3, 4.4, \dots \]

          \end{remark*}

    }}
\end{center}

\section{Convergence}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence Convergence
      \end{definition}
      \textbf{Informal Definition.}
      \par A sequence $ \{ a_{n }\} $ converges to a limit $ L $
      if the terms get arbitrarily close to $ L $ as $ n $
      gets sufficiently large, which is also known as

      \[ \lim_{n\rightarrow\infty}a_{n} = L \]
      \par
      \textbf{Formal Definition.}
      \par A sequence $ \{ a_{n}\} $ converges to a limit $ L $
      if, for every $ \varepsilon > 0 $, where $ \varepsilon $ is the distance from
      the range to the limit $ L $, there exists such a number
      that
      \[ |a_{n}- L| < \varepsilon ~\textrm{for}~ n \geq N \]

      The preceding expression is also known as the $ \varepsilon - N $ proof.
      \[ \]
    }}
\end{center}

\section{Divergence}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence Divergence
      \end{definition}
      \textbf{Informal Definition.}
      \par
      A sequence diverges when it doesn't converge. If the sequence
      $ \{ a_{n }\} $ does not get arbitrarily close to limit $ L $
      as $ n $ gets sufficiently large. This is also known as
      when the limit $ L $ \textbf{does not exist.}
      \par
      \[ \lim_{n\rightarrow\infty}a_{n} ~ \textrm{does not exist}\]
      \textbf{Formal Definition.}
      \par
      A sequence $ { a_{n} }$ diverges to (positive) infinity if, for every
      $ M > 0 $, there exists an N such that
      \[ a_{n} > M ~ \textrm{whenever}~ n > M \]

      Additionally, a sequence $ { a_{n} } $ diverges to negative
      infinity, if, for every $ M < 0 $, there exists an $ N $
      such that
      \[ a_{n} < M ~ \textrm{whenever} ~ n > M \]

    }
  }
\end{center}

\section{$\varepsilon-N$ Proof}
In this proof, we are proving the existence of a limit
when given a sequence $a_{n}$
\section{Properties of Sequence Limits}

% Sequences (Part Three)
\chapter{10.1: Sequences (Part 3) (03/31/23)}
\section{Summary of Lesson}
In this lesson, we further develop the idea of convergence
and divergence by \textbf{expanding it to non-elementary sequences}. We
apply several new theorems as a result of this, such as the
Sandwich Theorem. The homework, as a result, is all about
convergence and divergence, testing on how well we are
able to determine convergence and divergence given sequences
including factorials, logarithms, and exponential functions.
\section{Reminders}
\begin{itemize}
  \item The \textbf{third MyLab Math assignment} (Sequences
        (Part 2)) is due on \textbf{Tuesday, April 3rd}.
  \item The second written assignment is due on \textbf{
        Friday, April 7, 2023}.
\end{itemize}
\section{Motivation}


In the previous lesson, we learned about the \textbf{precise
  definition of convergence and divergence}. We learned about
what exactly convergence and divergence means, and we were
able to apply these concepts to various elementary sequences.
However, what if we were given a sequence like
\[ \{a_{n}\} = \frac{\cos(n)}{n}\]
Additionally, what if we were given a sequence like
\[ \{a_{n}\} = \Biggr( 1 + \frac{x}{n} \Biggr)^{n}\]

These sequences are undoubtedly more complex than our former
examples and are not nearly as intuitive whenever it comes to
actually solving them.
\par Therefore, we need to learn a few more \textbf{theorems} as
well as \textbf{techniques} in order to determine convergence
and divergence in more complex sequence functions.
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Sandwich Theorem
      \end{thm}
      Let $ \{a_{n}\}$, $ \{b_{n}\}$, $ \{ c_{n}\}$ be sequences
      of real numbers. If $ a_{n} \leq b_{n} \leq c_{n} $ holds for all
      $ n $ beyond some index $ N $, and if $ \lim_{n \rightarrow \infty }a_{n} =
      \lim_{n \rightarrow \infty } c_{n}= L $, then $ \lim_{n \rightarrow L } b_{n} = L $ also.
      \[ \textrm{let}~ \{a_{n}\},\{b_{n}\}, \{c_{n}\} ~ \textrm{
          be sequences
        }\]
      \[ \textrm{if}~ a_{n} \leq b_{n} \leq c_{n}~\textrm{and}  \]
      \[ \lim_{n \rightarrow \infty}a_{n} = L~\textrm{and}~\lim_{n \rightarrow \infty}c_{n}= L,~
        \textrm{then}\]
      \[ \lim_{n \rightarrow \infty} b_{n} = L\]
    }
  }
\end{center}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        The Continuous Function Theorem For Sequences (Theorem 3)
      \end{thm}
      Let $ \{a_n\}$ be a sequence of real numbers $ \R $. If $ a_{n} \rightarrow L $ and if $ f $ is a function
      that is continuous at $ L $ and defined at all $ a_{n}$ then $ f(a_{n}) \rightarrow f(L) $.
      \\
      \\
      \textbf{Informal Definition.}
      \\
      Essentially, as long as we know that if a sequence $ a_{n}$ exists and approaches some limit $ L $, we are able to say that
      if some function $ f $ is also continuous and the value $ f(L)$ exists and that the function $ f$ is defined for all terms
      in the sequence $ a_{n}$, then we know that the function with a domain of the terms of the sequence $ a_{n}$, which we
      represent as $ f(a_{n})$ will approach the value of the function $ f $ at the limit $ L $, which is also represented as the
      function $ f(L)$.
    }
  }

  \subsection{Importance of the Continuous Function Theorem for Sequences }
  The implication of the continous function theorem for sequences, of course, is that we can derive smaller, more
  trivial functions from a larger function. For example, if we were trying to solve for
  \[ \lim_{n \rightarrow \infty} \sqrt{\frac{2n}{n+1}}\]
  by using the \textbf{continuous function theorem for sequences}, we are able to separate this problem into a function, in
  which the domain is just a sequence $ a_{n}$ (or another function).
  \[ \textrm{let} ~ f(x) = \sqrt{x}, ~ \textrm{let} ~ x(n) = \frac{2n}{n+1} \]
  Now, we are able to evaluate the limit of the inner function.
  \[ \lim_{n \rightarrow \infty} \frac{2n}{n+1} \Rightarrow \frac{2n/n}{n/n+1/n} \Rightarrow \frac{2}{1} \Rightarrow 2 \]
  Knowing that the domain of the function $ f(x) $ will always approach 2, we are able to evaluate the outer limit.
  \[ \lim_{n \rightarrow \infty} \sqrt{\frac{2n}{n+1}} \Rightarrow \lim_{n \rightarrow \infty} \sqrt{2} = \sqrt{2}\]


\end{center}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Theorem 4. (L'Hopital's Rule)
      \end{thm}
      Suppose that $ f(x)$ is a function defined for all $ x \geq n_{0}$ and that $ \{a_{n}\}$ is a sequence of real numbers
      $ \R $ such that $ a_{n} = f(n)$ for $ n \geq n_{0}$. Then,
      \[ \lim_{n \rightarrow \infty } a_{n} = L ~\textrm{wherever}~ \lim_{n \rightarrow \infty}f(x) = L \]
      \textbf{Warning.}
      We cannot say the same about the converse of this theorem. That is, we  cannot say that as long as a sequence approaches
      infinity, that a function $ f $ with a domain of the terms of the sequence $ a_{n} $ will converge at a a limit $ L$.
      For example, imagine that if we had some high-degree polynomial expression and we had a sequence that converged at 0. The function itself might have several roots, as it will intersect the x-axis numerous times at zero. Ultimately however,
      the polynomial might not approach 0, but value of the function at the terms $ a_{n}$ might suggest it does.
    }
  }
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Theorem 5. (Commonly Occuring Limits)
      \end{thm}
      The following six sequences converge to the following limits listed below:
      \begin{enumerate}
        \item $ \lim_{n \rightarrow \infty} \frac{\ln(n)}{n} = 0 $
        \item $ \lim_{n \rightarrow \infty} \sqrt[n]{n} = 1 ~ \Longleftrightarrow ~ \lim_{n \rightarrow \infty} n^{1/n} = 1 $

        \item $ \lim_{n \rightarrow \infty} x^{1/n} = 1 ~ \textrm{for all} ~ (x > 0)$
        \item $\lim_{n \rightarrow \infty} x^{n} = 0 $
        \item $ \lim_{n \rightarrow \infty} \Biggr( 1 + \frac{x}{n}\Biggr)^{n} = e^{x} ~\textrm{for all $ x $}$
        \item $ \lim_{n \rightarrow \infty} \frac{x^{n}}{n!} = 0 ~ \textrm{for all $ x $}$

      \end{enumerate}
    }
  }
\end{center}




\chapter{4.6, 10.1: Finishing Sequences +  Newton's Method (04/03/2023)}
\section{Reminders}
\begin{itemize}
  \item The \textbf{third MyLab Math assignment} (Sequences
        (Part 2)) is due on \textbf{Tuesday, April 3rd}.
  \item The second written assignment is due on \textbf{
        Monday, April 10th, 2023}.
\end{itemize}
\section{Recall}
In the previous section, remember how we essentially continued to enrich our understanding of sequences and limits.
More specifically, we learned a few more theorems about sequence convergence and divergence.
\par First, let's start by actually talking about some patterns we see with the behavior of sequences. Recall
that when we talk about sequences, we are essentially just talking about a function, in which the domain are the indices of the
sequence (which indicate the position of the elements within the sequence) of which are natural numbers, that have a range of real numbers.
\par Convergence and divergence in a sequence refers to whether or not the sequence approaches some tangible, finite number
as the domain of the sequence (the indices) approach infinity. This, of course, is the \textbf{informal definition of
  sequence convergence}.
\par The \textbf{formal definition of sequence convergence} states that, in order for a sequence to converge to some value $ L $, there must exist some value $ \varepsilon $ after some point $ N $ in the sequence, in which all terms $ a_{n} $ of the sequence for $ n > N $ satisfy
\[ | a_{n} - L | < \varepsilon ~\textrm{where} ~ n > N \]

This basically states that, after some point in the sequence (denoted by the index $ N $), all terms of the sequence $ a_{n}$ must
fall within the range $ ( L - \varepsilon, L + \varepsilon )$, where $ \varepsilon $, of course, represents any arbitrarily small number.
\par Likewise, we can state that a sequence \textbf{diverges} when this behavior doesn't occur, which makes sense, as if there
exists no point in the sequence $ N $ where all consecutive terms all exist within some infinitesmially small range, then they
simply cannot be approaching any number in the first place.
\par In addition to this basic idea of convergence, we also learn about some restrictions as well as some implications that
arise from convergence.
\par For example, if we simply just want to determine whether or not a sequence converges, all we have to do is just solve
for the limit of that sequence. We just treat the sequence $ a_{n} $ as some function $ f(n) $ for all $ a_{n} $. This, of course
has a ton of different implications.
\begin{itemize}
  \item The \textbf{Sandwich Theorem} states that, if we have three sequences $ \{ a_{n}\} \{b_{n}\} \{c_{n}\}$, and that the
        sequence $ a_{n} $ approaches $ L$, and that the sequence $ c_{n} $ approaches $ L $, if the sequence $ b_{n} $ is
        between $ a_{n}$ and $ c_{n}$ (that is, $ a_{n} \leq b_{n} \leq c_{n}$), then $ \lim_{n \rightarrow \infty} b_{n} = L $.
        \[ \textrm{let} ~ \{a_{n}\}, \{b_{n}\}, \{c_{n}\}\]
        \[ \textrm{if} ~ \lim_{n \rightarrow \infty}a_{n} = L = \lim_{n \rightarrow \infty}c_{n}=L\]
        \[ \lim_{n \rightarrow \infty} a_{n} \leq \lim_{n \rightarrow \infty} b_{n} \leq \lim_{n \rightarrow \infty} c_{n}\]
        \[ \lim_{n \rightarrow \infty} b_{n} = L \]
  \item The \textbf{Continuous Function Theorem for Sequences} states that, if we have a function that is continuous for
        all values of $ x \geq n_{0}$ (such that $ n_{0}$ is the initial index of a sequence) and that there is a corresponding
        sequence $ a_{n} $ such that $f $ is defined and continuous for all values $ a_{n}$ and is continuous at $ L $, then
        we are able to say that the function of the domain $ a_{n}$ approaches the function value of the limit $ L $.

        Essentially, from this informs us that if there is a function $ f $ that is defined for all values of a sequence $ a_{n}$,
        as long as the $ a_{n} $ converges at a limit $ L $, then function $ f $ of which its domain is an expression of $ n $$
        a_{n} $, then the function $ f(a_{n}) $ must converge at $ f(L) $. This allows us to state that if we are trying to
        find evaluate the limit of a function, we are able to dissect the function into an outer function $ f(x) $ and an
        inner expression $ x(n) $. The procedure from here is that we are able to find the limit of this inner function $ x(n) $,
        substitute it as the domain of the outer function, then evaluate the final limit of the outer function.
  \item Additionally, like all other limits, we are able to evaluate the value at which a sequence converges to
        by using \textbf{L'Hopital's Rule}. The technical definition of L'Hopital's Rule states that if there exists a function
        $ f(n) = a_{n}$, then the limit of the function $ \lim_{n \rightarrow \infty} f(n) = L $ always implies that
        $ \lim_{n \rightarrow \infty} a_{n} = L $. If we are able to evaluate the limit of the sequence as a limit of a function,
        then we are able to assert that the limit of the sequence is equal to the limit of that function. On the converse,
        however, we are unable to assert that if a function converges at a limit, then the sequence of that function will
        also converge at that limit. This all really just comes down to the idea that sequences are not functions.
  \item Finally, after this, there are just some important, well-known and already proven sequence convergences that
        I will be tested on. It is important to understand these for later, since they are pretty essential to solving
        many future sequence problems.


\end{itemize}

\section{Motivation}
For this lecture, we are literally just finishing up sequences and getting ready to move onto the next topic, series. We spent
this class just learning about one final piece of the puzzle in series, which is \textbf{monotonicity} and the
\textbf{monotonicity convergence theorem}.
\section{Types of Sequences}
Recall that through this section, we have thought about sequences in two different ways: \textbf{explicitly} and
\textbf{recursively}.
\subsection{Explicit Sequences}
An explicit sequence is a sequence in which the value of the term of the sequence $ a_{n}$ is determined only by the
index $ n $. We don't need information about other terms in the sequence, as we are able to compute the value of any
term of the sequence \textit{solely} based on its position.
\subsection{Examples of Explicit Sequences}
\[ a_{n} = n + 1, ~ a_{n} = \frac{n}{2} \]
\subsection{Recursive Sequences}
A \textbf{recursive sequence} is a sequence in which the value of a term in the sequence is computed using the previous
term of the sequence. It might be helpful to think of this as recursion in computer science, as we are literally just taking
a previous output as input in this function. Generally, whenever we denote a recursive function, we will say that the
term FOLLOWING the current term is equal to some expression of the current term.
\subsection{Examples of Recursive Sequences}
\[ a_{n+1} = a_{n} + 1, ~ a_{n+1} = \frac{a_{n}}{2}\]



\section{Defining Divergence}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence Divergence (Towards Infinity)
      \end{definition}
      A sequence $ \{ a_{n} \}$ diverges to positive infinity if for all $ M $, there is an $ N $ such that $ a_{n} > M $
      for all $ n > N $
     }
  }
\end{center}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence Divergence (Towards Negative Infinity)
      \end{definition}
      A sequence $ \{ a_{n}\}$ diverges to negative infinity if for all $ M $, there is an $ N $ such that $ a_{n} < N $ for
      all $ n > N $.
     }
  }
\end{center}

When we read these definitions, we can imagine that the $ M $ is just some upper and lower bound or threshold. If, after
some point in the sequence $ a_{n} $, all subsequent terms $ a_{n} $ are all above or below a particular threshold, it makes
sense that they would just approach infinity. This idea of divergence, however, all depends on the idea of
\textbf{monotonicity}.

\section{Monotonicity}
\textbf{Monotonicity} defines a sequences general shape and behavior. A series is monotonous as long all of its values
all pertain to some behavior.
\\
\subsection{Nondecreasing Monotonic Sequences}
A \textbf{nondecreasing monotonic sequence} is a sequence in which, as the name suggests, the terms do not decrease.
More precisely, we can say that
\[ a_{n} \leq a_{n+1} \]
\subsection{Nonincreasing Monotonic Sequences}
A \textbf{nonincreasing monotonic sequence} is a sequence in which the terms do not increase. More precisely,
\[ a_{n} \leq a_{n+1} \]

\subsection{Monotonic Convergence}
We can apply the idea of monotonicity, that is, the idea that a function bears only a single behavior into limits. In fact,
there is actually an entire theorem dedicated to this idea.

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Monotonic Convergence Theorem
      \end{thm}
      If a sequence \[ \{a_{n}\}\] is both bounded and monotonic, then it converges.

      \textbf{Informal Definition.}
      \\
      For a sequence is a nonincreasing, that is $ a_{n} \geq a_{n+1} $, if all terms after some point $ N $ are
      less than or equal to the greatest possible lower bound $ L $, then we can
      say that the bounded, monotonicaly nonincreasing sequence $ a_{n}$ converges at that greatest possible lower bound $ L $.
      \\
      Likewise, for a sequence that is nondecreasing, or $ a_{n} \leq a_{n+1}$, if all terms after some point $ N $ are
      less than or equal to the least possible upper bound $ L $, then we can say that the bounded monotonically nondecreasing
      sequence $ a_{n} $ converges at $ L $.
    }
  }
\end{center}

\section{Newton's Method}
TODO

\section{Introduction to Series}
A series is just an expression of the form
\[ a_{1} + a_{2} + a_{3} + a_{4} + \cdots \]
Imagine that we are just taking a sequence  $ a_{n}$ and then
we are just trying to find the sum of the terms $ a_{n} $ for
all values of $ n $.
\\
This, howver, is particularly hard to compute, since after all
,if we were trying to find the sum of an infintie amount
of termsl ike in the following series
\[ \sum_{n=1}^{\infty} a_{n}\]
would be impossible. In order to mediate this, we have a
few tricks in which we can actaully break up series in order
to the actual sum of the series.

\subsection{Sequence of Partial Sums }
In the previous section, we just introduced the idea of a
sequence. A sequence, of course its composed of its terms $ a_{n}$ as well as its indices $ n $. For sake of argument, however, let us consider having a sequence in which each term is the sum of the current term and all of the terms preceding it. For reference
\[ \textrm{let} ~ \{a_{n}\} \]
\[ S_{1} = a_{1}\]
\[ S_{2} = a_{1} + a_{2}\]
\[ S_{3} = a_{1} + a_{2} + a_{3}\]
\[ S_{4} = a_{1} + a_{2} + a_{3} + a_{4} \]
\[ S_{n} = a_{1} + a_{2} + a_{3} + a_{4} + \cdots \]

Notice that the sequence of partial sums for $ n $ terms
looks \textbf{suspiciously} simialr to the idea of infinite
series\dots because it they're the same thing! Whenever we
are thinking of a series, we can just contextualize it as
just being a sequence of partial sums for the $ n $th term.
\\
This recontextualization of the series as just a sequence
of partial sums to the $ n$th term (as opposed to the
first term of the second term), is very \textbf{powerful},
since it will grant us a beter understanding of how exactly
the the series works, how to compute operations with it,
as well as working with series convergence and divergence.

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence of Partial Sums
      \end{definition}
      Given a sequence of numbers $ \{ a_{n}\}$, an
      expresssion of the form
      \[ a_{1} + a_{2} + a_{3} + a_{4} + \cdots \]
      is called an \textbf{infinite series}. The number $ a_{n} $ is the \textbf{$n$th term} of the series. The
      sequence $ \{ S_{n}\}$ defined by
      \[ s_{1} = a_{1} \]
      \[ s_{2} = a_{1} + a_{2}\]
      \[ s_{n} = a_{1} + a_{2} + \cdots + a_{n-1} + a_{n}
        = \sum_{k=1}^{n} a_{k }\]
      is the \textbf{sequence of partial sums} of the series,
      the number $ s_{n} $ begin the \textbf{$ n$th partial
        sum.} If the sequence of partial sums converges
      to a limit $ L $, we say that the series \textbf{
        converges} and that its \textbf{sum} is $ L $.
    }
  }
\end{center}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Sequence of Partial Sums (cont'd.)
      \end{definition}
      \textbf{Intuition.}
      \\
      Previously, we talked about this idea of contextualizing
      a series as the sum of a sequence up until a certain
      point. For example,

      \[ \sum_{n=1}^{2}a_{n} = a_{1} + a_{2}\]
      \[ \sum_{n=1}^{3}a_{n} = a_{1} + a_{2} + a_{3}\]

      This is all pretty cool, but lets apply this
      idea of finding the series of every single term in a
      sequence $ a_{n} $ and then putting these series (which, of course, really only refers to the sum
      of the series) \textbf{within a sequence}.

      \[ \{S_{n}\}  = S_{1} + S_{2} + S_{3} + \cdots +
      S_{n} \]
    \[ \{S_{n}\} = \sum_{n=1}^{1} a_{n} + \sum_{n=1}^{2} a_{n} +
    \sum_{n=1}^{3} a_{n} + \cdots + \sum_{n=1}^{n} a_{n} \]

  Note, the sequence of partial sums is \textbf{not
    equivalent} to the series itself. (After all, the sequence of partial sums is literally just a
  sequence and additionally, the series we are
  analyzing is just a term within the sequence). The
  sequence of partial sums is just a
  collection of all possible series up until our
  given series $ n $. This
  is useful, because we can think of the value or sum of the
  series as being equal to the limit of the sequence
  of its partial sums. This idea of thinking of the
  value of a series as the limit of sequence of partial
  sums at some point $ n $ is extremely powerful and allows
  us to work within the framework of series convergence
  and divergence.
    }
  }
\end{center}

\subsection{Methodology for solving for the sum of a series}
In order to solve for the sum of a series, we again have
to consider numerous factors:
\begin{itemize}
  \item The series $ \sum_{n=1}^{\infty} a_{n}$ can also be represented as the point of convergence or limit for the sequence of partial sums $ \{ S_{n}\} $ where
        \[ S_{n} = \sum_{n=1}^{1} a_{n} + \sum_{n=1}^{2} a_{n} +
        \cdot + \sum_{n=1}^{n} a_{n}\]
  \item We know how to compute the limit $ L $ or point of
        convergence of a sequence, as well as how to
        determine whether not a sequence actually
        converges or not.
\end{itemize}
From this, we can consider the following steps:
\begin{enumerate}
  \item Let the terms of the series be a sequence.
  \item Evaluate the partial sums for the first few terms.
  \item Determine the ``pattern'' between these
        terms.
        \begin{itemize}
          \item The ``pattern'' here is eventually
                going to transform into the ``function'' of
                a sequence. We are going to determine a
                rule between the partial sums.
        \end{itemize}

  \item Let this pattern be a function/algorithm for
        computing future terms.
  \item Let this pattern be the function of a
        sequence of partial sums $ \{S_{n}\} $
  \item Determine whether or not the sequence of partial
        sums $ \{S_{n}\} $ converges or diverges. If the
        sequence converges, then determine at what point
        it converges to. The point at which the sequence
        of partial sums converges to, or the result of
        the series at some point $ n $, is going to be
        known as the \textbf{sum} of that series.

\end{enumerate}

\section{Example of Series Sums}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{remark*}[\textbf{1}]
        Determine the sum of the series
        \[ 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
        \frac{1}{16} + \cdots \]
      \end{remark*}
      \textbf{Step 1:} Let the terms of the series
      be a sequence.
      \[ \textrm{let} ~ \{a_{n}\} = 1, \frac{1}{2},
        \frac{1}{4}, \frac{1}{8}, \frac{1}{16}, \cdots \]
      \textbf{Step 2:} Evaluate the partial sums for
      the first few terms of the sequence (which we made
      through the terms of the series).
      \[ \textrm{let} ~ \{S_{n}\} ~\textrm{be the sequence
          of partial sums for $ a_n $ } \]
      \[ \{S_{n}\} = S_{1}, S_{2}, S_{3}, \cdots, S_{n}\]
      \[ S_{1} = 1 = 1 \]
      \[ S_{2} = 1 + \frac{1}{2}  = \frac{3}{2}\]
      \[ S_{3} = 1 + \frac{1}{2} + \frac{1}{4} = \frac{7}{4} \]
      \[ S_{n} = 1 + \frac{1}{2} + \frac{1}{4} +
      \frac{1}{8} + \cdots + \frac{1}{2^{n-1} } = \frac{2^{n} - 1 }{2^{n-1}}\]

    }
  }
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{remark*}[\textbf{(1) cont'd}]
      \end{remark*}
      \textbf{Step 3:} Let the pattern in the sequence of
      partial sums be the function of the sequence of partial
      sums.
      \[ \textrm{let $S_{n}$} ~ = \frac{2^{n}-1}{2^{n-1}}\]
      \textbf{Step 4:} Determine whether or not the
      sequence of partial sums converges or diverges.
      Find the limit if the sequence converges.
      \[ \lim_{n \rightarrow \infty} S_{n} =
        \lim_{n \rightarrow \infty} \frac{2^{n}-1}{2^{n-1}}\]
      \[ \Rightarrow \lim_{n \rightarrow \infty } \frac{2^{n}}{2^{n-1}} - \lim_{n \rightarrow \infty } \frac{1}{2^{n-1}}\]
      \[ \Rightarrow 2 - 0 \]
      \[ \lim_{n \rightarrow \infty} \frac{2^{n}-1}{2^{n-1}} = 2 \]
      \textbf{Step 5:} Let the limit or point of convergence
      of the sequence of partial sums be the
      sum of the series in question.
      \[ 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} +
        \cdots = \lim_{n \rightarrow \infty} \frac{2^{n}-1}
        {2^{n-1}} = 2 \]

      The sum of the series given by $ 1 + \frac{1}{2} +
      \frac{1}{4} + \frac{1}{8} + \cdots $ is 2.
    }}
\end{center}

\subsection{Series Notation}
Whenever we are trying to denote a sequence, we observe
the following kinds of notation:
\[ \textrm{let} ~ a_{n} ~\textrm{be some expression for $ n $}\]
\[ \sum_{n=1}^{\infty} a_{n}, ~ \sum a_{n}\]
The left notation $ \sum_{n=1}^{\infty} a_{n}$, of course, is more specific, letting us know what index
we should start the series at as well as giving us a terminal point,
which although strange, is just infinity in the case of the first example.
\\
\\
In the second case $ \sum a_{n}$, we are just demonstarting that $ a_{n}$ is just a series,
similar to how we just denote sequences with just curly braces $ \{ a_{n}\}$.

\subsection{Introduction to Series Convergence and Series Divergence}
Again, just to reiterate what we have learned in the past section, whenever we are rying to determine whether or not a series converges or diverges, we are essentially trying ot determine whether the sum or the evaluation of the series is going to be some finite number. We can always try to imagine this kind of like a Riemann sum beneath a curve
\begin{itemize}
  \item Recall that whenever we were trying to solve a
        Riemann sum, we were always trying to estimate the
        area underneath a curve by using rectangles. In
        that same kind of sense, we are trying to see
        if the sum generated by the series, which is
        going to be one of these ``rectangels'' beneath
        the graph of a function of the series, is going
        to be finite.
\end{itemize}

So, in order to determine whether or not a series is
convergent or divergent, we first have to transform
the series into a sequence of partial sums, where the
domain of course is going to be natural numbers that
are determiend by the indicies of the sequence and the
range is going to be determined by the sum of the
sequence of hte function (which is distince from
the sequence of partial sums) at that point.
\\
Therefore, when the sequence of partial sums converges,
this can be thought of as the series if the series
just appproaches infinity.
\\
Whenever we are trying to determien whether or not the
series diverges, we just want to see if the sequence
of partial sums that we obtain through the series
actually converges or not. Whenever the sequence of
partial sums does not converge, then it must diverge.


% 10.2 (Part One): Infinite Series (Part One) (4/05/23)
\chapter{10.2 (Part One): Infinite Series (Part One) (4/05/23)}
\section{Reminders}
\begin{itemize}
  \item The \textbf{fifth MyLab Math assignment: Infinite Series}, will be due on
        \textbf{Sunday, April 9th, 2023}.

  \item The second written assignment is due on \textbf{
        Monday, April 10th, 2023}.
\end{itemize}

\section{Motivation}
In the last section, we obtained a taste of what
series were and how we are able to interpret them. Most
prominently, we can imagine that a series can be considered
as a term in a sequence, where all other terms in the
sequence are just series up until a particular point.
This concept is known as the \textbf{sequence of partial
  sums}. Whenever we are evaluating the sequence of partial
sums, it is important that we understand this distinction.

\par Recall that we denote sequences with the following notation:
\[ \sum_{n}^{k} a_{n} ~\textrm{for the specific case }\]
\[ \sum a_{n} ~\textrm{for the general case}\]
\[ a_{1} + a_{2} + a_{3} + a_{4} + \cdots \]

\par This is how we represent series as partial sums.
\[ \textrm{let} ~ \{ S_{n}\} ~\textrm{be a sequence of partial sums}\]
\[ \textrm{let} ~ \{ s_{n}\} ~\textrm{be a function denoting the partial sum of $ n $}\]
\[ \{S_{n}\} = S_{1}, S_{2}, S_{3}, S_{4}, \cdots \]
\[ \{S_{n}\} = \sum_{n=1}^{1} s_{n},~ \sum_{n=1}^{2} s_{n},~
  \sum_{n=1}^{3} s_{n},~ \sum_{n=1}^{4} s_{n}, ~\cdots, ~ \sum_{n=1}^{n} s_{n}\]

\par Whenever we are trying to determine \textbf{series convergence and divergence},
we have to be able to contextualize or infinite series as the convergence
point of a \textbf{sequence of partial sums}. The convergence point of the
infinite series, therefore must be the convergence point of the
sequence of partial sums. This, of course, does present us with many
different things to consider whenever we are evaluating for partial sums. We have
seen how we can evaluate a series whenever it is just given to us in the form

\[ a_{1} + a_{2} + a_{3} + a_{4} + \cdots \]

We basically think of these terms as the sequence $ a_{n} $, then we just
create separate sequence $ S_{n} $ that represents the partial sums of
the terms of the sequence $ a_{n}$. Then, we have to represent this
sequence $ S_{n} $ as some function or algorithm. After we have
derived an algorithm for the sequence of partial sums $ S_{n} $, we can
determine the convergence of the sequence of partial sums $ S_{n} $ by
evaluating
\[ \lim_{n \rightarrow \infty} S_{n}\]

By finding the point of convergence for the sequence of partial sums,
we have determined both whether or not the series converges, but
also where the series converges to. By evaluating a series, we have
found its \textbf{sum}.

\subsection{What's on the Menu}
Now that we have learned the basic idea of what series are, we need
to understand that not all series are this nice. Unfortuantely,
series, much like sequences, can become much more complicated and complex
in their terms, and for this reason, we also need to learn some new
techniques, methodologies, and patterns for which to evaluate
these series (that is, whenever we are evaluating for a series, we are
really just determining their point of convergence / limit).

\section{Commonly Seen Series}
\subsection{Geometric Series
}
\fbox{
  \parbox{\textwidth}{
    \begin{definition}[\textbf{10.2 (1)}]
      Geometric Series
    \end{definition}
    Geometric series are series of the following form
    \[ a + ar + ar^{2} + \cdots + ar^{n-1} + \cdots \]
    \[ \Rightarrow \sum_{n=1}^{\infty} ar^{n-1} \]
    in which $ a $ and $ r $ are fixed real numbers and
    $ a \neq 0 $. The series can also be written as
    \[ \sum_{n=0}^{\infty}ar^{n} \]
    \textbf{Notation}
    \\
    The variable $ r $ is known as the \textbf{ratio} of the
    geometric series and $ a $ is known as the initial term.
    \begin{itemize}
      \item Of course, the reason why we call $ a $ the
            initial term of the geometric sequence is because
            whenever n is equal to the initial index of the series,
            1
            \[ar^{n-1} \Rightarrow ar^{1-1} \Rightarrow a \]
    \end{itemize}
    $ r $ can be either a positive or negative number, as observed in the
    two following series.
    \[ \textrm{let} \sum a_{n}, ~ \textrm{let} \sum b_{n}\]
    \[ \sum a_{n} = \sum_{n=1}^{\infty} \frac{1}{2}(1^{n})\]
    \[ \sum b_{n} = \sum_{n=1}^{\infty} \frac{1}{2}((-1)^{n})\]

  }}


\subsection{Geometric Series Convergence and Divergence}
Recall that whenever we are trying to determine whether or not a series
converges or diverges, we are trying to contextualize the series as a
term within a \textbf{sequence of partial sums}.
\[ \textrm{let} ~ \{S_{n}\} ~ \textrm{be a sequence of partial sums}\]
\[ \textrm{let} ~ s_{n} ~ \textrm{be a function denoting the partial sum at some index $ n $}\]
\[ \{S_{n}\} = s_{1} , s_{2} , s_{3} , s_{4} , \cdots , s_{n}\]
\[ \{S_{n}\} = \sum_{n=1}^{1}s_{n} , \sum_{n=1}^{2} s_{n} ,
  \sum_{n=1}^{3} s_{n}, \sum_{n=1}^{4}s_{n}, \cdots, \sum_{n=1}^{n} s_{n}    \]

From this, we know that the limit of the sequence of partial sums $ \sum_{n=1}^{\infty}s_{n}$ is
equal to the sum of a series.

\par In the most general case of a geometric series, recall that
we obtain the following form:
\[ \textrm{let $\sum S_{n}$ be some geometric series (that is, some fucntion)}\]
\[ \textrm{let the function of $ \sum S_{n}$ be } ar^{n-1} \]
\[ \sum S_{n} = S_{1} + S_{2} + S_{3} + S_{4} + \cdots + S_{n}  \textrm{ \textbf{Write the $ n$th partial sum}}\]
\[ \Rightarrow \sum S_{n} = ar^{1-1} + ar^{2-1} + ar^{3-1} + ar^{4-1} + \cdots a^{n-1} \]
\[ \Rightarrow \sum S_{n} = ar^{0} + ar^{1} + ar^{2} + ar^{3} + \cdots a^{n-1} \]
\[ \Rightarrow \sum S_{n} = a + ar + ar^{2} + ar^{3} + \cdots a^{n-1} \]
\[ \Rightarrow
  r\sum S_{n} = r(ar^{1-1} + ar^{2-1} + ar^{3-1} + ar^{4-1} + \cdots ar^{n-1}) \textrm{ \textbf{Multiply both sides by $ r $} }\]
\[ \Rightarrow
  S_{n} - r\sum S_{n} = (a + ar + ar^{2} + ar^{3} + \cdots + ar^{n-1} ) - (ar + ar^{2} + ar^{3} + ar^{4} + \cdots + ar^{n})
\]
Here, we now subtracting $ r\sum S_{n}$ from $ S_{n} $. We just introduce $ S_{n} $.

\[ S_{n} - r\sum S_{n} = a - ar^{n}\]
Notice all terms except for the initial term $ a $ and the
terminating term $ a ^{n} $ are left. Let's factor both sides now.

\[ S_{n} (1 - r) = a (1 - r^{n}) \]

\[ S_{n} = \frac{a(1-r^{n})}{(1-r)} \textrm{for all $ r $ where $ r \neq 1 $} \]

Now that we have a general function to solve for the sum of the geometric series $ \sum S_{n} $,
let us try to determine what values of $ r $ that the geometric sequences converges and
diverges.

\[ \textrm{let $ \sum S_{n} $ be geomtric series} \]
\[ S_{n} = ar^{n+1}\]
\[ \Rightarrow S_{n} = S_{1} + S_{2} + S_{3} + \cdots + S_{n} \]
\[ \Rightarrow S_{n} = ar^{1-1} + ar^{2-1} + ar^{3-1} + \cdots + ar^{n-1} \]
\[ \Rightarrow S_{n} = a + ar + ar^{2} + \cdots + ar^{n-1} \]
\[ \Rightarrow r(S_{n}) = r(a + ar + ar^{2} + \cdots + ar^{n-1}) \]
\[ \Rightarrow r(S_{n}) = ar + ar^{2} + ar^{3} + \cdots + ar^{n} \]
\[ \Rightarrow S_{n} - r(S_{n}) = S_{n} - (ar + ar^{2} + ar^{3} + \cdots + ar^{n}) \]
\[ \Rightarrow (a + ar + ar^{2} + ar^{3} + \cdots + ar^{n-1}) - (ar + ar^{2} + ar^{3} + \cdots + ar^{n-1} + ar^{n}) \]
\[ \Rightarrow S_{n} - r(S_{n}) = a - ar^{n} \]
\[ \Rightarrow S_{n} (1 - r) = a(1 - r^{n}) \]
\[ \Rightarrow S_{n} = \frac{a(1-r^{n})}{(1-r)} \textrm{ for all $ r \neq 1 $ }\]

This formula $ S_{n} = \frac{a(1-r^{n})}{(1-r)} $ represents the sum or value of any geometric series. However,
how can we use this formula to determine the convergence and divergence of a geometric series?

\subsection{Convergence and Divergence of the Geometric Series}
      Let us observe the behavior of the sum of a geometric series.
      \\
      \\
      \textbf{Recall.}
      \\

      The sum of a geometric series is equal to the following equation:
      \[ \sum S_{n} = \frac{a(1-r^{n})}{(1-r)}\]
      \textbf{Definition.}
      \[ \textrm{let $ \sum S_{n} $ be a geometric series} \]
      \[ S_{n} = \sum_{n=1}^{\infty} ar^{n-1} \]
      In order to determine the convergence of a geometric series,
      we must determine the limit of the sum  of the geometric series.
      \[ \lim_{n \rightarrow \infty}  S_{n} = \lim_{n \rightarrow \infty} \frac{a(1-r^{n})}{(1-r)} \]

      Let us look at the dominate term of the function, $ r_{n} $. Observe
      that when the absolute value of r is greater than one  $ | r| > 1$, the term $ r^{n} $
      will approach infinity. However, whenever the absolute value of r is
      less than 1 $ | r| < 1$, $r^{n}$ will just approach 0, since all values less than one will
      only get smaller when exponentiated.

      Therefore, we know that for the geometric series $ \sum S_{n} $, its value or sum diverges
      when the ratio $ r $ is greater than one.
      \[ S_{n} = \lim_{n \rightarrow \infty} \frac{a(1-r^{n})}{(1-r)} = \infty \textrm{ when $ | r| > 1 $ } \]

      On the other hand, whenever the value of the ratio $ r $ is less than one or $ | r| < 1 $, we know
      that the ratio itself is only going to get smaller and smaller, eventually approaching 0, meaning
      that the value of the infinite series will converge.

      \[ S_{n} = \lim_{n \rightarrow \infty} \frac{a(1-r^{n})}{(1-r)} \textrm{ for $ |r| < 1$  }\]
      \[ \Rightarrow S_{n} = \lim_{n \rightarrow \infty} \frac{a(1-0)}{(1-r)} = \frac{a}{(1-r)}\]



\subsection{Geometric Series Examples}
%10.2 (Part Two): Infinite Series (Part Two) (04/07/23)
\chapter{10.2 (Part Two): Infinite Series (Part Two) (04/07/23)}
\section{Reminders}
\begin{itemize}
  \item The \textbf{fifth MyLab Math assignment: Infinite Series}, will be due on
        \textbf{Sunday, April 9th, 2023}.

  \item The second written assignment is due on {Monday, April 10th, 2023}.
\end{itemize}
\section{Summary}
In this lecture, we essentially expanded on what we learned about series in the previous
lecture.
Recall how we learned about geometric series, their formation, as well as how we
determine whether or not they converge or diverge. Most importantly, we also
learned how to manipulate the values of a series in order to determine
an equation for finding the sum of a geometric series.
\par All of this culminates into today's lesson, which is all about
determinign the convergence of other types of series.
\section{Recall}
Over our introduction and talks about series, we have gone over
different methods and algorithms for determining the value of a
sequence as well as determining convergence and divergence.
\subsection{Convergence and Divergence in Series}
Remember, convergence and divergence in regards to series refers
to the sum of the series as the terms of the series approach infinity.
This can be represented through the following notation:
\[ \sum_{n=1}^{\infty}S_{n} = a_{1} + a_{2} + a_{3} + a_{4} + \cdots + a_{n} \]
Given this general form of a how a series works, we can actually
recontextualize the terms of the series as a sequence
\[ \{a_{n}\} = a_{1}, a_{2} , a_{3}, a_{4}, \dots, a_{n} \]
This is important because we can actually create a new separate sequence
$ \{ S_{n}\}$, where each term is a series up until that term
in the sequence
\[ \{S_{n}\} = S_{1}, S_{2}, S_{3}, S_{4}, \dots, S_{n}\]
\[ \{S_{n}\} = (a_{1}), (a_{1} + a_{2}), (a_{1} + a_{2} + a_{3}), \dots, (a_{1} + a_{2} + a_{3} + \cdots + a_{n} ) \]
This final term $ S_{n} = (a_{1} + a_{2} + a_{3} + \cdots + a_{n} ) $ is equivalent
to the series $ \sum S_{n} $. The value of a series is equivalent to the
$n$th term of a sequence of partial sums. In order to evaluate the value and the
series convergence, then, is to just determine the convergence of the sequence
of partial sums. The point at which the sequence of partial sums converges to
is equivalent to the sum of the series.
\\
\\
Now, this pattern of course works for trivial and elementary series,
since all it requires is the ability to find the pattern
between the terms in the sequence of partial sums. We can just
apply sequence convergence methods and tricks in order to compute
this. But, what happens when we want to determine if a more
complex sequence converges or diverges? What if, for example, we
had a geometric sequence?
\par A geometric sequence is a sequence that occurs in the following form

\[ \sum_{n=1}^{\infty} a \cdot r^{n-1} = a + ar + ar^{2} + ar^{3} + \cdots + ar^{n-1}\]

A geometric series, thankfully, has a general equation that allows us to compute its
sum and value.

\[ \textrm{let $S_{n}$ be the value of a geometric sequence} \]
\[ S_{n} = \frac{a(1-r^{n})}{(1-r)} \]
Using this equation, we can deduce that all values of the ratio $ r $ that are greater
than 1, or $ |r| > 1 $ are going to \textbf{diverge}, while all values of the ratio
$ r $ that are less or equal to 1, or $ |r| \leq 1$ are going to \textbf{converge} at
the following value:

\[ \lim_{n \rightarrow \infty} \frac{a(1-r^{n})}{(1-r)} = \frac{a}{(1-r)} \textrm{ when $|r| \leq 1 $} \]

Otherwise, all other geometric sequences will \textbf{diverge.}


\section{Motivation}
Given now that we know how a general algorithm for computing the value and convergence/divergence
of a series as well as how to find series convergence and divergence given a particular type
of series, let us learn some new techniques in order to compute the value of a series
as well as series convergence and series divergence.

\section{Partial Fraction Decomposition for Series}
TODO

\section{Telescoping Series}
TODO

\section{nth-term Divergence Test}
How can we actually determine when a series converges
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Theorem 7
      \end{thm}
      \[ \textrm{If } \sum_{n=1}^{\infty} a_{n} \textrm{ converges, then $ a_{n} $ approaches 0.}\]
      \textbf{Warning.}
      \\
      We cannot say the same for the \textbf{converse} of this. Just because i
    }}
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        The nth-term divergence test
      \end{thm}
      The series
      \[ \sum_{n=1}^{\infty} a_{n} \]
      diverges if the limit of the function of the series function $ a_{n}$ fails to exist or is not equal to 0.
        \[ \sum_{n=1}^{\infty} \textrm{ converges when } \lim_{n \rightarrow \infty} a_{n} \neq 0 \textrm{ or does not exist. }\]
      }
    }
\end{center}


\section{Combining Series}
Now that we have learned some general ideas about series, let us talk about
some operations we can do with series.

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}[8]
        Combining Series Theorem (Theorem 8)
      \end{thm}
      \[ \textrm{Let $ \sum a_{n} = A $ and $ \sum b_{n} = B $ be convergent series}\]

      \begin{itemize}
        \item Sum Rule:
              \[ \sum (a_{n} + b_{n})  = \sum a_{n} + \sum b_{n} = A + B \]

        \item Difference Rule:
              \[ \sum (a_{n} - b_{n}) = \sum a_{n} - \sum b_{n} = A - B \]

        \item Constant Multiple Rule:
              \[ \sum k a_{n} = k \sum a_{n} = kA \textrm{ for all values of $ k $ } \]

      \end{itemize}

    }
  }

\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \textbf{Proof.} Series Sum Rule
      \[ \textrm{let $ \sum a_{n} = A $ and $ \sum b_{n} = B $}\]
      \[ A = a_{1} + a_{2} + a_{3} + a_{4} + \cdots + a_{n}  \]
      \[ B = b_{1} + b_{2} + b_{3} + b_{4} + \cdots + b_{n}\]
      \[ \textrm{ let $ S_{n} $ be equal to $ \sum (a_{n} + b_{n})$}\]
      \[ S_{n} = (a_{1} + a_{2} + a_{3} + \cdots + a_{n}) + (b_{1} + b_{2} + b_{3} + \cdots + b_{n})\]
      \[ \Rightarrow S_{n}= (a_{1} + b_{1}) + (a_{2} + b_{2}) + (a_{3} + b_{3}) + (a_{4} + b_{4}) + \cdots
        (a_{n} + b_{n}) \]
      \[ \Rightarrow S_{n} = A_{n} + B_{n}\]

    }
  }
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \textbf{Proof.} Series Difference Rule
      \[ \textrm{let $ \sum a_{n} = A $ and $ \sum b_{n} = B $}\]
      \[ A = a_{1} + a_{2} + a_{3} + a_{4} + \cdots + a_{n} \]
      \[ B = b_{1} + b_{2} + b_{3} + b_{4} + \cdots + b_{n} \]
      \[ \textrm{ let $ S_{n}$ be equal to $ \sum (a_{n} - b_{n})$} \]
      \[ S_{n} = \sum a_{n} - \sum b_{n}  \]
      \[ S_{n} = (a_{1} + a_{2} + a_{3} + \cdots + a_{n}) -  (b_{1} + b_{2} + b_{3} + \cdots + b_{n})\]
      \[ S_{n} = (a_{1} - b_{1}) + (a_{2} - b_{2}) + (a_{3} - b_{3}) + \cdots + (a_{n}- b_{n})\]
      \[ S_{n} = A - B \]
    }
  }
\end{center}


\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \textbf{Proof.} Series Constant Multiple Rule
      \[ \textrm{let $ \sum a_{n} = A $ and $ k $ be some constant }\]
      \[ \sum a_{n} = A = a_{1} + a_{2} + a_{3} + \cdots + a_{n} \]
      \[ \textrm{ let $ S_{n} $ be equal to $ \sum (k \cdot a_{n}) $}\]
      \[ S_{n} = k \cdot a_{1} + k \cdot a_{2} + k \cdot a_{3} + \cdots + k \cdot a_{n} \]
      \[ S_{n} = k (a_{1} + a_{2} + a_{3} + \cdots + a_{n})\]
      \[ S_{n} = k \cdot A = k \sum a_{n} \]
    }
  }
\end{center}


% 10.3: The Integral Test (04/05/23)
\chapter{10.3: The Integral Test (04/05/23)}
\section{Reminders}
\begin{itemize}
  \item The fifth \textbf{MyLab Math: Infinite Series} is due on
        \textbf{Sunday, April 9th, 2023}.
  \item The second \textbf{Written Homework: Infinite Series} is due on
        \textbf{Monday, April 10th, 2023}.
\end{itemize}

\section{Motivation}
In the previous section, we expanded our knowledge and understanding
of infinite series convergence and divergence by observing some
other types of infinite series as well as how to approach them.
\begin{itemize}
  \item Namely, we learned about the \textbf{nth term divergence test},
        \textbf{combining series}, as well as other types of series
        manipulation, such as \textbf{telescoping series} and
        \textbf{partial fraction decomposition}.

\end{itemize}

\subsection{Recap: nth term divergence test}
TODO
\subsection{Recap: Combining Series}
TODO
\subsection{Recap: Telescoping Series}
TODO
\subsection{Recap: Partial Fraction Decomposition}
TODO

\section{Integral Test}

% 10.4: Comparision Tests (04/07/23)
\chapter{10.4: Comparision Tests (04/07/23)}
\section{Reminders}

\begin{itemize}
  \item The fifth \textbf{MyLab Math: Infinite Series} is due on
        \textbf{Sunday, April 9th, 2023}.
  \item The second \textbf{Written Homework: Infinite Series} is due on
        \textbf{Monday, April 10th, 2023}.
\end{itemize}

\section{Motivation}
In the previous lesson, we discussed a technique known as the
\textbf{integral test for series convergence.} Essentially,
we use this technique to determine whether or not a given series
converges or diverges by comparing it to its integral. After all,
whenever we do have a series, we can always think about it like
a \textbf{Riemann Sum}, or at least, some botched version of a
Riemann Sum. The function created by the series, however, can
also be graphed as a function. What we end up doing is just
graphing both the series as a series as well as the series as a
function and then compare their behavior. If we can determine
that the integral of the series as a function is finite,
then we can reasonably say that the limit of the series must
also be finite, and therefore must converge.

\section{The Comparison Test}
\subsection{Intuition}
Whether or not a sequence converges or diverges
depends on its \textbf{tail}, or the movement
of the sequence as the index $ n $ approaches infinity,
which is also deonted as $ n \rightarrow \infty $.

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        The Comparison Test
      \end{definition}
      \[ \sum_{n=1}^{\infty} a_{n} \textrm{ converges if
          and only if } \sum_{n=k}^{\infty} a_{k}
        \textrm{ converges, where $ k $ is some value
          after $ n $} \]
      We can think of the difference between these
      two sums as
      \[ \sum_{n=1}^{\infty} a_{n} - \sum_{n=k}^{\infty} a_{n}
        = \sum_{n=1}^{k} a_{n} \]
      since we can think of the resulting sum
      as the series terms $ a_{n} $ between $ n $ and $ k $,
      or $ 1 < n < k $.
      \par From this, we know that if
      \[ 0 \leq a_{n} \leq b_{n} ~ \forall n, \textrm{ then }\]
      \begin{enumerate}
        \item If $ \sum b_{n} $ converges, then
              this implies $ \sum a_{n} $ also converges
        \item If $ \sum a_{n} $ diverges, then
              this implies that $ \sum b_{n} $
              also diverges
              (to $ \infty$)
      \end{enumerate}
    }
  }
\end{center}

\subsection{Comparison Test Proof}
\begin{remark*}
Assume that $ \sum a_{n} $ diverges to $ + \infty$.
Show that $ \sum b_{n} $ also diverges to $ + \infty$.
\end{remark*}

\[ 0 \leq a_{n} \leq b_{n} \]

\[\textrm{let $A_{n} = \sum_{k=1}^{n} a_{k}$ and
    $B_n = \sum_{k=1}^{n}b_{k}$. }\]

We must demonstrate that $\forall M, \exists N $, such that
$ B_{n} > M $, $\forall n > N $. (We must demonstrate
that for all M, there exists such a value N that
$ B_{n} > M $ for all values of $ n > N $, where
M is some lower bound of $ B_{n} $ and $ n$ and $ N$ are indices
of the series).
\section{P-Series Test}
TODO
\section{Limit Comparison Test}
TODO









% 10.5: Absolute Convergence and the Ratio Test
\chapter{10.5: Absolute Convergence and the Ratio Test}
\section{Reminders (MATH\_226)}
\begin{itemize}
  \item There are practice pracice problems on \textbf{MyLab Math} that have unalimited attempts and no due date.
  \item \textbf{MyLab Math 6: Integral Test} and
        \textbf{MyLab Math 7: Comparison Tests} are due on
        \textbf{Tuesday, April 11, 2023} and \textbf{Thursday,
        April 13, 2023}, respectively.
  \item There is a written homework that is due at the beginning of class on \textbf{Friday, April 14, 2023}.
        \item \textbf{MATH\_226 Midterm 1} is on \textbf{Tuesday, April 18, 2023}
\end{itemize}

\section{Reminders (MATH\_230-1)}
\begin{itemize}
  \item \textbf{MyLab Math 6: Planes in Space} is due on
        \textbf{Thursday, April 13, 2023}.
  \item \textbf{Written Homework 1} is due on
        \textbf{Wednesday, April 12, 2023}.
\end{itemize}



\section{Motivation}
In the previou sclasses we have learned about when a series converges as well as how to test for that.
However, in order to supplmeent our learning we need to learn about how to build functions from series

\[ 1 + x + x^{2} + \cdots \Rightarrow \frac{1}{1-x}, \textrm{ $ |x | \leq 1 $ } \]

\section{Direct Comparison Test (Part 2)}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Direct Comparison Test
      \end{definition}
      TODO
    }
  }
\end{center}

\section{Limit Comparison Test}
\subsection{Intuition}
Recall the \textbf{Constant Multiple Rule for Sequences}, which essentially
stated that if there were two sequences $ \{a_{n}\} $ and
$ \{ ca_{n}\}$, where $ c $ is just a constant, then we
know that, although $ \{ ca_{n}\} \neq \{ a_{n}\} $, both
sequences would just have the same behavior, since they'd
basically just be the same sequences, just with different
scales.

\par We can, of course, just apply this to series, since
the series
\[ \sum_{n=1}^{\infty} c \cdot a_{n} = c \sum_{n=1}^{\infty} a_{n}\]
\[ \Rightarrow \sum a_{n} \textrm{'s behavior} \Rightarrow c \sum a_{n}
\textrm{'s behavior}\]

The idea here is that, what if we just thought of
two sequences or series as scaled versions of the other. What if we
could determine that scale? What would the scale imply?

Introduce the \textbf{Limit Comparison Test}.

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Limit Comparison Test
      \end{definition}

      Suppose $ a_{n} > 0 $ and $ b_{n} > 0 $ for all $ n > N $.
      \\
      \\


      \[ \lim_{n \rightarrow \infty} \frac{a_{n}}{b_{n}} =
        \begin{cases}
          C > 0, ~ \textrm{then $ \sum a_{n} $'s behavior $ \Leftrightarrow $
          $ \sum b_{n} $'s behavior } \\
          0, ~ \textrm{then $ \sum b_{n} $'s conv. $ \Rightarrow $ implies $ \sum a_{n}$'s conv.}  \\
          \infty, ~ \textrm{then $ \sum a_{n} $'s conv.
          $ \Rightarrow$ implies $ \sum b_{n} $'s conv. }
        \end{cases}\]

      The contrapositive is also true,
            \[
        \lim_{n \rightarrow \infty} \frac{a_{n}}{b_{n}} =
        \begin{cases}
          C > 0, ~ \textrm{then $ \sum a_{n} $'s behavior $ \Leftrightarrow $
          $ \sum b_{n} $'s behavior } \\
          0, ~ \textrm{then $ \sum a_{n} $'s div. $ \Rightarrow $ implies $ \sum b_{n}$'s div.}  \\
          \infty, ~ \textrm{then $ \sum b_{n} $'s div.
          $ \Rightarrow$ implies $ \sum a_{n} $'s div. }
        \end{cases}
      \]
    }}
\end{center}

      \subsection{Intuition (Part 2.)}
      The main idea here is that, we want to analyze the ratio
      of $ a_{n} $ and $ b_{n}$  to determine which function is
      \textbf{greater than the other}. If some function is less than or
      equal to another function, and the greater function converges,
      then the lesser function must also converge logically. Vice
      versa, if the lesser function diverges, then the greater
      function must also diverge logically.


\section{Absolute Convergence Test}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Absolute Convergence
      \end{definition}

    }
  }
\end{center}


\section{The Ratio Test and the Root Test}
\subsection{Underlying Intuition...}
Recall that whenever we started to learn about the geometric series,
we obsessed over the following notation

\[ \sum_{n=1}^{\infty} a \cdot r^{n} \]

We talked about the idea of the varialbe $ r $ as a ratio that was \textbf{very related}
to the series' convergence and divergence behavior.
\begin{itemize}
  \item More specifically, as long as the ratio $ | r | \leq 1 $, then the value $ r^{n} $ would
        eventually converge to 0, which meant that the function $ \frac{a(1-r^{n})}{1-r} $ would
        converge.
  \item The contrapositive to this, that $ | r | \geq 1 $ meant that the value $ r^{n} $ would
        \textbf{diverge}.
\end{itemize}

This same idea applies here. If we were given a geometric series, for example, and we
wanted to isolate this ratio $ r $, there are a number of ways to do so.

We are able to isolate the variable $ r $ be analyzing \textbf{successive terms} with
the following function:
\[ \textrm{let $ \sum a_{n}$ be a geometric series} \]
\[ \Rightarrow \frac{ar^{n+1}}{ar^{n}} = r \]

as well as by isolating the variable $ r $ by analyzing the \textbf{nth root} of any
term in the series:
\[ \textrm{let $ \sum a_{n}$ be a geometric series}\]
\[ \Rightarrow \sqrt[n]{ar^{n}} = r \]

To take this a step further, let us take this discussion
about the variable $ r $ outside the realm of purely
geometric series. We are able to actually apply these ratios
to non-specifically geometric functions, such as functions
with fractions as well as factorials. The idea is that it does
not matter whether or not there is some consistent ratio between
all terms, but rather, that there is some ratio that we approach
\textbf{at a limit}.

From this, we can observe the following equations


\subsection{Ratio Test}
Essentially, we want ot be able to analyze the ratio $ r $ in a
series of the form
\[ \sum_{n=1}^{\infty} ar^{n} \]

We want to analyze the $ r $, since we can recall that as long as $ |r| < 1 $, then
the series will converge.

% 10.6: Alternating Series and Conditional Convergence
\chapter{10.6: Alternating Series and Conditional Convergence (04/12/23)}

\section{Reminders}
\begin{itemize}
  \item \textbf{MyLab 7: Comparison Tests} is due
        \textbf{tomorrow, Thursday, April 13, 2023}.
  \item \textbf{Written Assignment 3: Comparison Tests}
        is due on \textbf{Friday, April 14, 2023}.
\end{itemize}

\section{Objectives}
TODO
\section{Recall}
TODO

\section{Motivation}
But what if we see a series that comes in this form:
\[ 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \cdots +
  \frac{(-1)^{n+1}}{n} + \cdots \]
or this?
\[ -2 + 1 - \frac{1}{2} + \frac{1}{4} - \frac{1}{8} +
\cdots + \frac{(-1)^{n}4}{2^{n}} + \cdots\]

As we will see, these are known as
\textbf{Alternating Series}, and are particularly notable
series because they have a particular methdology of
assessing convergence and divergence.
\section{Alternating Series Test}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Alternating Series Test (Theorem 15)
      \end{thm}

      The series denoted as

      \[ \sum_{n=1}^{\infty} (-1)^{n+1} u_{n} =
        u_{1} - u_{2} + u_{3} - u_{4} + \cdots \]
      converges \textbf{if and only if} the following
      conditions are satisfied:
      \begin{enumerate}
        \item All values of $ u_{n} $ are positive
        \item All values of $ u_{n} $ are
              \textbf{eventually nonincreasing}, meaning
              that $ u_{n} \geq u_{n+1} $ for all $ n \geq N $
              for some integer $ N $.
        \item The values $ u_{n} $ eventually approach
              0.
      \end{enumerate}


    }
  }
\end{center}

\subsection{Alternating Series Intuition}
Whenever we are working with alternating series, it is
important to think of $ u_{n} $ as the terms, but rather,
the partial sums of the terms at $ n $.
We want to emphasize the differences between $ u_{n} $ and $ u_{n+1}$, thinking about  the \textbf{
  difference between the partial sums}  $ u_{n}$.

\par If we were geometrically observing the
values of $ u_{n} $, we would imagine that the partial
sums of the series are narrowing down, almost like a
funnel. The idea here is that, if were were to
calculate all partial sums of the series $ u_{n} $,
we would find that they all approach a single value,
and therefore, converge. We need the
values of $ u_{n} $ (the difference between the
partial sums of $ a_{n} $ and $ a_{n+1} $) to be positive because TODO.
\par The difference between the partial sums $ u_{n} $ and
$ u_{n+1} $ also needs to be decreasing, forming
this ``cone'' shape. If the differences between the
partial sums is decreasing, then the difference
will eventually approach 0, then we can state
that the actual sum of the series will stop at
some limit $ L $.
\begin{center}
  \textbf{TODO: Insert Graphic displaying the difference}
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{corollary}
        Alternating Harmonic Series Divergence
      \end{corollary}
      The alternating harmonic series
      \[ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n} \]
      is \textbf{conditionally convergent}, since
      we know that although the alternating harmonic
      series does diverge by using the
      \textbf{alternating series test}, we know
      that the absolute valu eof the alternating
      harmonic series is equal to the harmonic series,
      which we know diverges by the integral test.
      \[ \sum_{n=1}^{\infty}\frac{|(-1)^{n+1}|}{|n|}
        \Rightarrow \sum_{n=1}^{\infty} \frac{1}{n}
      \Rightarrow \textbf{ which diverges}\]
    }
  }
\end{center}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Alternating Series Estimation Theorem (by
        Prof. Zaslow)
      \end{thm}
      Whenever a series is convegent
      by the \textbf{Alternating
        Series Test}, then we must know that the
      absolute value of the
      remainder $ |R_{n}| \leq u_{n+1} $ for all
      $ n \geq N $, where $ |R_{n}| $ represents
      the difference between the partial
      sums $ u_{n} $ of the series.
      \[ |R_{n} | \leq u_{n+1} \]

    }}
\end{center}






\subsection{Alternating Series Proof}
TODO
\subsection{Examples}

\begin{remark*}[\textbf{1}]
  Alternating Harmonic Series
\end{remark*}

\begin{remark*}[\textbf{2}]
  Non-Increasing Example
\end{remark*}


\section{Alternating Series Estimation Theorem}

\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Alternating Series Estimation Theorem (Theorem 16)
      \end{thm}
      If the alternating series
      \[ \sum_{n=1}^{\infty} (-1)^{n+1}u_{n} \] satisfies
      all three conditions of the \textbf{Alternating Series
        Test (Theorem 15)}, then for $ n \geq N $,
      \[ s_{n} = u_{1} - u_{2} + \cdots + (-1)^{n+1} u_{n}\]
      approximates the sum $ L $ of the series with an
      error whose absolutye value is less than
      $ u_{n+1}$, the absolute value of the first unused
      term. Furthermore, the sum $ L $ lies between
      any two successive partial sums $ s_{n} $ and
      $ s_{n+1}$ and the remainder, $ L - s_{n} $ has the
      same sign as the first unused term.
    }

  }
\end{center}

\subsection{Alternating Series Estimation Theorem Intuition}
TODO
\subsection{Examples}
\begin{remark*}[\textbf{3}]

\end{remark*}

\section{Conditional Convergence}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{definition}
        Conditional Convergence
      \end{definition}
      A series that is convergent but not
      \textbf{absolutely convergent} is called
      \textbf{conditionally convergent}.
    }
  }
\end{center}

\subsection{Conditional Convergence Intuition}
TODO

\section{Rearranging Series}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{thm}
        Rearrangement Theorem for Absolutely Convergent
        Series (Theorem 17)

      \end{thm}

      If
      \[ \sum_{n=1}^{\infty} a_{n} \]
      converges absolutely, and the sequene
      \[ b_{1}, b_{2}, b_{3}, \cdots, b_{n}, \cdots \]
      is any arrangement of the sequence $ \{a_{n}\}$,
      then $ \sum b_{n} $ converges absolutely and
      \[ \sum_{n=1}^{\infty} b_{n} = \sum_{n=1}^{\infty} a_{n}\]


    }
  }
\end{center}

\subsection{Rearranging Series Intuition}

\section{Summary of Tests to Determine Convergence or
  Divergence}
\begin{center}
  \fbox{
    \parbox{\textwidth}{
      \begin{enumerate}
        \item The nth-Term Test for Divergence
        \item Geometric Series
        \item p-series
        \item Series with nonnegative terms
        \item Series with some negative terms
        \item Alternating Series


      \end{enumerate}

    }
  }
\end{center}




% 10.6: Strategies for Analyzing Convergence
\chapter{10.6: Strategies for Analyzing Convergence}
\section{Reminders}
\section{Motivation}

%%%%%%%%%%%% MIDTERM 1 DONE %%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{10.7 (Part One): Power Series}
\section{Reminders}
\section{Motivation}
\chapter{10.7 (Part Two): Radius and Interval of Convergence}
\section{Reminders}
\section{Motivation}
\chapter{10.7 (Part Three): Manipulation of Series (Part One)}
\section{Reminders}
\section{Motivation}
\chapter{10.7 (Part Four): Manipulation of Series (Part Two)}
\section{Reminders}
\section{Motivation}
\chapter{10.8 (Part One):}
\section{Reminders}
\section{Motivation}
\chapter{10.8 (Part Two):}
\section{Reminders}
\section{Motivation}
\chapter{10.9: Convergence of Taylor Series}
\section{Reminders}
\section{Motivation}
\chapter{10.10: Applications of Taylor Series}
\section{Reminders}
\section{Motivation}
\chapter{A7 (Part One): Complex Numbers (Part One)}
\section{Reminders}
\section{Motivation}
\chapter{10.10, A7 (Part Two): Complex Numbers (Part Two)}
\section{Reminders}
\section{Motivation}
\chapter{19.1 (Part One): Vectors}
\section{Reminders}
\section{Motivation}
\chapter{19.1 (Part Two): Inner Products}
\section{Reminders}
\section{Motivation}
%%%%%%%%%%%% MIDTERM 2 DONE %%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{19.2 (Part One): Functions as Vectors, Periodic
  Functions}
\section{Reminders}
\section{Motivation}
\chapter{19.2 (Part Two): Fourier Series, Demos}
\section{Reminders}
\section{Motivation}
\chapter{19.3: Fourier Series, Theory}
\section{Reminders}
\section{Motivation}
\chapter{19.5 (Part One): Applications (Part One)}
\section{Reminders}
\section{Motivation}
\chapter{19.5 (Part Two): Applications (Part Two)}
\section{Reminders}
\section{Motivation}
\end{sloppypar}

\end{document}
